{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bcebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "from utils import load_and_filter_dataset, one_hot_encode_sequence, create_graph_from_sequence, summarize_dataset\n",
    "from dataset import PiRNADataset\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d76e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_11016\\2234487913.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  data = load_and_filter_dataset(\"data\\DASHR2_GEO_hg38_sequenceTable_export.csv\", save_filtered=True)\n",
      "c:\\Users\\lenovo\\Desktop\\RNAGEN\\utils.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=None, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 1 non-numeric values in 'len' column. These rows will be excluded from filtering.\n",
      "Dataset Summary (Before Filtering):\n",
      "  Total entries: 65156\n",
      "  RNA types: 13\n",
      "rnaClass\n",
      "piRNA           50397\n",
      "snRNA            4509\n",
      "miRNAprimary     1881\n",
      "rRNA             1840\n",
      "scRNA            1420\n",
      "mir-3p            959\n",
      "mir-5p            957\n",
      "mir-5p3pno        897\n",
      "tRNA              631\n",
      "tRF3              631\n",
      "tRF5              631\n",
      "snoRNA            402\n",
      "rnaClass            1\n",
      "Name: count, dtype: int64\n",
      "-----------------------------------------\n",
      "Filtered Dataset:\n",
      "  Total piRNAs with length 26â€“32: 50397\n",
      "  Unique piRNA IDs: 23116\n",
      "  Length range in filtered data: 26.0 - 32.0\n",
      "Filtered data saved to data/filtered_piRNAs.csv\n"
     ]
    }
   ],
   "source": [
    "data = load_and_filter_dataset(\"data\\DASHR2_GEO_hg38_sequenceTable_export.csv\", save_filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37f0512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 40317, Val samples: 5040, Test samples: 5040\n",
      "\n",
      " Train set processed and saved to: dataset\\train\n",
      "\n",
      " Summary for train set:\n",
      "Total samples: 40317\n",
      "Sequence length: mean = 32.00, std = 0.00, min = 32, max = 32\n",
      "Label distribution: {27.0: 5626, 31.0: 4619, 30.0: 8687, 28.0: 5138, 29.0: 8186, 32.0: 1271, 26.0: 6790}\n",
      "Average nodes per graph: 32.00\n",
      "Average edges per graph: 62.00\n",
      "Node feature shapes: {(32, 5)}\n",
      "Label shapes: {(1,)}\n",
      "\n",
      " Val set processed and saved to: dataset\\val\n",
      "\n",
      " Summary for val set:\n",
      "Total samples: 5040\n",
      "Sequence length: mean = 32.00, std = 0.00, min = 32, max = 32\n",
      "Label distribution: {30.0: 1081, 28.0: 635, 26.0: 893, 29.0: 962, 32.0: 181, 31.0: 606, 27.0: 682}\n",
      "Average nodes per graph: 32.00\n",
      "Average edges per graph: 62.00\n",
      "Node feature shapes: {(32, 5)}\n",
      "Label shapes: {(1,)}\n",
      "\n",
      " Test set processed and saved to: dataset\\test\n",
      "\n",
      " Summary for test set:\n",
      "Total samples: 5040\n",
      "Sequence length: mean = 32.00, std = 0.00, min = 32, max = 32\n",
      "Label distribution: {30.0: 1091, 28.0: 583, 27.0: 719, 26.0: 840, 31.0: 580, 29.0: 1051, 32.0: 176}\n",
      "Average nodes per graph: 32.00\n",
      "Average edges per graph: 62.00\n",
      "Node feature shapes: {(32, 5)}\n",
      "Label shapes: {(1,)}\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "output_root = \"dataset\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "for split_name, split_df in zip(['train', 'val', 'test'], [train_df, val_df, test_df]):\n",
    "    split_path = os.path.join(output_root, split_name)\n",
    "    os.makedirs(split_path, exist_ok=True)\n",
    "    \n",
    "    dataset = PiRNADataset(root=split_path, df=split_df)\n",
    "    print(f\"\\n {split_name.capitalize()} set processed and saved to: {split_path}\")\n",
    "    \n",
    "    summarize_dataset(dataset, split_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c83ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels=5, hidden_channels=32, out_channels=64):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.gcn3 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.gcn3(x, edge_index)  \n",
    "        \n",
    "        if batch is not None:\n",
    "            x = global_mean_pool(x, batch)\n",
    "        else:\n",
    "            x = x.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16ecf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_gcn_encoder(num_nodes, num_node_features, hidden_dim, out_channels, num_edges):\n",
    "    x = torch.randn(num_nodes, num_node_features)\n",
    "    edge_index = torch.randint(0, num_nodes, (2, num_edges), dtype=torch.long)\n",
    "\n",
    "    model = GCNEncoder(in_channels=num_node_features, hidden_channels=hidden_dim, out_channels=out_channels)\n",
    "    out = model(x, edge_index) \n",
    "    \n",
    "    return out.shape\n",
    "\n",
    "test_out_shape = test_gcn_encoder(num_nodes=32, num_node_features=5, hidden_dim=32, out_channels=64, num_edges=62)\n",
    "print(test_out_shape)  # Expect torch.Size([1, 64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd14a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
